import os
import json
from pathlib import Path

import gradio as gr
from vertexai import init

from rag_pipeline import RAGPipeline
from crawl_xiaohongshu_board import crawl_xiaohongshu_board
from embedding_database import MilvusStorage

# ---------- VertexÂ AI credential & init ----------
KEY_PATH = "./my-gemini-key.json"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = KEY_PATH

with open(KEY_PATH, "r") as f:
    PROJECT_ID = json.load(f)["project_id"]

# æ ¹æ®ä½ çš„åŒºåŸŸè°ƒæ•´
init(project=PROJECT_ID, location="us-central1")

# ---------- Milvus / Collection settings ----------
COLLECTION_NAME = "xiaohongshu_content"
DB_PATH = "./milvus_demo.db"
FLAG_PATH = Path(".xhs_loaded.flag")   # æŠ“å–å®Œæˆçš„æ ‡å¿—æ–‡ä»¶

# ---------- Helper : ensure vectors only loaded once ----------
def ensure_vectors_loaded(favorite_url: str):
    """If flag exists, skip crawling. Otherwise crawl + insert + create flag."""
    if FLAG_PATH.exists():
        return  # å·²æŠ“å–è¿‡

    # --- æŠ“å–å°çº¢ä¹¦æ”¶è—å¤¹ ---
    df = crawl_xiaohongshu_board(favorite_url)

    # --- å†™å…¥å‘é‡æ•°æ®åº“ ---
    storage = MilvusStorage(collection_name=COLLECTION_NAME, db_path=DB_PATH)
    storage.insert_data(df)

    # --- åˆ›å»º flag æ–‡ä»¶ ---
    FLAG_PATH.touch()

# ---------- RAG æ¨ç† ----------
def answer_query(query: str):
    pipeline = RAGPipeline(
        collection_name=COLLECTION_NAME,
        db_path=DB_PATH,
        top_k=3,
        temperature=0.7,
        model_name="gemini-1.5-pro"
    )
    return pipeline.answer(query)

# ---------- ChatInterface å›è°ƒ ----------
def rag_chat(user_message: str, history: list[tuple[str, str]], favorite_url: str):
    if not favorite_url.strip():
        return "Please paste the bookmark link on the left first, then ask questions."

    # ç¡®ä¿å‘é‡å·²åŠ è½½ï¼ˆé¦–æ¬¡ä¼šæŠ“å–å¹¶å†™å…¥ï¼‰
    ensure_vectors_loaded(favorite_url)

    # ç”Ÿæˆå›ç­”
    response = answer_query(user_message)

    answer = f"Question: {user_message}\n\n"
    answer += f"Answer: {response['answer']}\n\n"
    answer += "Source Document:\n"
    for i, src in enumerate(response["sources"], 1):
        answer += f"\n--- Source {i} ---\n"
        answer += f"Title: {src['title']}\n"
        answer += f"URL: {src['url']}...\n"
    return answer

# ---------- Gradio UI ----------
with gr.Blocks(title="Bookmark Assistant Bot Demo") as demo:
    gr.Markdown(
        """## ğŸ” Bookmark Assistant Bot
1. Paste the favorites link on the left
2. Enter keywords or questions in the chat box on the right
3. The backend will retrieve and generate answers"""
    )

    with gr.Row():
        favorite_box = gr.Textbox(
            label="ğŸ“ Bookmark link (required once)",
            placeholder="e.g., https://www.xiaohongshu.com/board/...",
            lines=1
        )

    chat = gr.ChatInterface(
        fn=rag_chat,
        additional_inputs=[favorite_box],
        examples=[["python"], ["cooking"]]
    )

# ---------- Start ----------
if __name__ == "__main__":
    demo.launch(share=False)